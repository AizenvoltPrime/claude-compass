# Claude Compass Environment Configuration
# Copy this file to .env and update the values for your environment

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Primary database URL (used by Knex and most database operations)
DATABASE_URL=postgresql://claude_compass:password@localhost:5432/claude_compass

# Individual database connection parameters (for Docker and direct connections)
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=claude_compass
DATABASE_USER=claude_compass
DATABASE_PASSWORD=password

# Database connection pool settings
DATABASE_POOL_MIN=2
DATABASE_POOL_MAX=10
DATABASE_POOL_IDLE_TIMEOUT=30000
DATABASE_POOL_ACQUIRE_TIMEOUT=60000

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level: error, warn, info, http, verbose, debug, silly
LOG_LEVEL=info

# Log file path (relative to project root)
LOG_FILE=logs/claude-compass.log

# Enable console logging (true/false)
LOG_CONSOLE=true

# Log format: simple, json, combined
LOG_FORMAT=simple

# =============================================================================
# MCP SERVER CONFIGURATION
# =============================================================================

# MCP server port for HTTP transport (future feature)
MCP_SERVER_PORT=3000

# MCP server host binding
MCP_SERVER_HOST=localhost

# Enable MCP server debug logging
MCP_DEBUG=false

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Environment: development, production, test
NODE_ENV=development

# Application port (for future web interface)
APP_PORT=8080

# Application host
APP_HOST=localhost

# =============================================================================
# PARSING CONFIGURATION
# =============================================================================

# Maximum file size to parse (in bytes, default: 1MB)
MAX_FILE_SIZE=1048576

# Maximum number of files to process per repository
MAX_FILES=10000

# File extensions to parse (comma-separated)
PARSE_EXTENSIONS=.js,.jsx,.ts,.tsx,.mjs,.cjs,.vue

# Include test files in analysis
INCLUDE_TEST_FILES=false

# Include node_modules in analysis (not recommended)
INCLUDE_NODE_MODULES=false

# =============================================================================
# EMBEDDING & GPU CONFIGURATION
# =============================================================================

# GPU batch size configuration for embedding generation
# Controls how many symbols are processed per batch during embedding generation
#
# MEMORY OPTIMIZATIONS (Automatic):
# - Arena shrinkage: ONNX Runtime releases memory after each batch (prevents fragmentation)
# - Arena extend strategy: Allocates exactly what's needed (prevents over-allocation)
#
# CALCULATION GUIDE:
# 1. Check your GPU VRAM: nvidia-smi --query-gpu=memory.total --format=csv,noheader
# 2. Estimate available VRAM: Total - Model overhead (1.5GB) - Safety margin (1GB)
# 3. Per-text memory usage: ~50-80MB per text (varies by text length)
# 4. Calculate batch size: Available VRAM / Per-text memory
#
# RECOMMENDED BATCH SIZES (with memory optimizations):
# - 6GB GPU (RTX 3060/4050):  Small repos=64,  Large repos=24-32
# - 8GB GPU (RTX 3070/4060):  Small repos=96,  Large repos=48-64
# - 12GB GPU (RTX 3080/4070): Small repos=128, Large repos=80-96
# - 24GB GPU (RTX 4090):      Small repos=256, Large repos=128-192
#
# Note: Arena shrinkage enables larger batch sizes than before without OOM
# Leave empty to use smart defaults based on repo size

# Batch size for GPU processing (small repositories < 5000 symbols)
EMBEDDING_BATCH_SIZE_GPU_SMALL=64

# Batch size for GPU processing (large repositories >= 5000 symbols)
# Increased from 16 to 24 due to arena shrinkage optimization
EMBEDDING_BATCH_SIZE_GPU_LARGE=24

# Batch size for CPU processing (small repositories)
EMBEDDING_BATCH_SIZE_CPU_SMALL=64

# Batch size for CPU processing (large repositories)
EMBEDDING_BATCH_SIZE_CPU_LARGE=32

# Threshold for considering a repository "large" (number of symbols)
EMBEDDING_LARGE_REPO_THRESHOLD=5000
